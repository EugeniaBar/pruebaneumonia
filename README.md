Dataset https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia 


# Detecci칩n de Neumon칤a en Radiograf칤as de T칩rax: Un Estudio de Caso de Aprendizaje Profundo

![NEUM](https://github.com/user-attachments/assets/e929f98f-b3bc-47a0-af86-40ac2a0be84b)

# Detecci칩n de Neumon칤a en Radiograf칤as de T칩rax: Un Estudio de Caso de Aprendizaje Profundo

---

## 游늯 Resumen del Proyecto

Este proyecto explora la aplicaci칩n de Redes Neuronales Convolucionales (CNNs) para clasificar radiograf칤as de t칩rax en dos categor칤as: **Normal** y **Neumon칤a**. A trav칠s de este trabajo, se compara el rendimiento de un modelo CNN entrenado "desde cero" con un modelo que utiliza la potente t칠cnica de **Transfer Learning** (VGG16), destacando los desaf칤os del entrenamiento con datasets limitados y la importancia de las estrategias de IA.

---

## 游 Objetivo de Aprendizaje

El prop칩sito principal de este proyecto es did치ctico:

* **Comprender las Limitaciones de CNNs desde Cero:** Demostrar c칩mo una red neuronal, incluso con aumento de datos, puede fallar en aprender patrones complejos y tender a la **memorizaci칩n (sobreajuste)** cuando el volumen de datos de entrenamiento es muy escaso.
* **Dominar el Transfer Learning:** Ilustrar la eficacia y la necesidad del Transfer Learning para tareas de clasificaci칩n de im치genes con datasets peque침os, aprovechando el conocimiento pre-entrenado de modelos de vanguardia.
* **Manejo de Datos:** Entender la importancia del balance del dataset y las implicaciones de las estrategias de submuestreo.
* **Interpretaci칩n de M칠tricas:** Aprender a leer y entender m칠tricas clave como Accuracy, Precision, Recall y AUC en el contexto de clasificaci칩n binaria, especialmente para evaluar la calidad del modelo.

---

## 游늬 Estructura del Dataset

El dataset utilizado consta de radiograf칤as de t칩rax, dividido en conjuntos de entrenamiento, validaci칩n y prueba. Cada conjunto est치 perfectamente **balanceado** con 240 im치genes de la clase "Normal" y 240 im치genes de la clase "Neumon칤a".

* **`DATOS235/`**
    * **`train/`**
        * `normal/` (240 im치genes)
        * `pneumonia/` (240 im치genes)
    * **`val/`**
        * `normal/` (240 im치genes)
        * `pneumonia/` (240 im치genes)
    * **`test/`**
        * `normal/` (240 im치genes)
        * `pneumonia/` (240 im치genes)

**Nota sobre el balance:** Se opt칩 por submuestrear las clases con m치s im치genes para lograr un balance perfecto. Si bien esto ayuda a prevenir el sesgo hacia la clase mayoritaria, es importante reconocer que se descart칩 una cantidad considerable de datos 칰nicos que podr칤an haber mejorado a칰n m치s el rendimiento general del modelo si se hubieran utilizado con otras estrategias (como ponderaci칩n de clases o aumento de datos para la minoritaria).

---

## 游빍 Enfoques Implementados y Conclusiones

Se exploraron dos enfoques principales para la clasificaci칩n de im치genes:

### 1. Modelo CNN Entrenado "Desde Cero"

* **Descripci칩n:** Se construy칩 una Red Neuronal Convolucional (CNN) con capas como `Conv2D`, `MaxPooling2D`, `BatchNormalization`, `Flatten`, `Dense` y `Dropout`, intentando variar el n칰mero de filtros (ej. 16-32-64, 32-64-128) y el `batch_size`. Se aplic칩 **aumento de datos (data augmentation)** extensivo para intentar diversificar el dataset limitado.

* **Resultados T칤picos en Test:**
    * Loss: ~2.1249
    * Accuracy: ~0.5000
    * Precision: ~0.5000
    * Recall: ~1.0000
    * AUC: ~0.8238

* **Conclusi칩n:** Este enfoque **fracas칩 en la generalizaci칩n**. Las m칠tricas de prueba (`Accuracy` del 50%, `Precision` del 50%, `Recall` del 100%) revelan un **sobreajuste severo y un sesgo**. El modelo no aprendi칩 a distinguir entre "Normal" y "Neumon칤a"; en su lugar, **simplemente memoriz칩 las im치genes de entrenamiento** y termin칩 prediciendo sistem치ticamente una sola clase (probablemente "Neumon칤a") para todas las entradas en los conjuntos de validaci칩n y prueba. La **cantidad extremadamente limitada de im치genes 칰nicas (480 en entrenamiento)** impidi칩 que la CNN aprendiera patrones robustos y generalizables, incluso con el apoyo de la data augmentation.

### 2. Modelo Basado en Transfer Learning (VGG16)

* **Descripci칩n:** Se utiliz칩 la arquitectura **VGG16**, un modelo pre-entrenado en el gigantesco dataset ImageNet. Se carg칩 VGG16 **sin sus capas clasificatorias (`include_top=False`)** y sus capas convolucionales se **congelaron (`layer.trainable = False`)**. Luego, se a침adieron capas personalizadas (`Flatten`, `Dense`, `Dropout`, `Dense(1, sigmoid)`) en la parte superior para la clasificaci칩n binaria. Se entren칩 esta nueva "cabeza" clasificatoria y, en una segunda fase, se realiz칩 un **fine-tuning** (descongelando las 칰ltimas capas convolucionales de VGG16) con un `learning_rate` m치s bajo.

* **Resultados Finales del Modelo (Fine-Tuned) en Test:**
    * Loss: **0.4427**
    * Accuracy: **0.9103** (91.03%)
    * Precision: **0.9138** (91.38%)
    * Recall: **0.9060** (90.60%)
    * AUC: **0.9608**

* **Detalle de Predicciones por Imagen (en el conjunto de Prueba):**
    * Total de im치genes en test: 468
    * **Correctos Positivos** (Neumon칤a correctamente predicha): 131
    * **Correctos Negativos** (Normal correctamente predicho): 228
    * **Falsos Positivos** (Normal predicho como Neumon칤a): 6
    * **Falsos Negativos** (Neumon칤a predicha como Normal): 103
    * Accuracy Calculado a partir de estas predicciones: 76.71% (Esta es una **discrepancia importante** a investigar; la precisi칩n de `model.evaluate` es la m치s fiable si el generador de prueba se usa correctamente).

* **Conclusi칩n:** El **Transfer Learning fue la estrategia funcional y exitosa**, logrando un rendimiento **muy bueno y equilibrado**. El modelo Fine-Tuned demostr칩 una alta **precisi칩n general (Accuracy)** y, crucialmente, una **excelente capacidad para identificar correctamente los casos de Neumon칤a (Recall: 90.60%)**, al mismo tiempo que mantiene una buena **Precisi칩n (Precision: 91.38%)**. Esto indica que el modelo no solo predice bien, sino que tambi칠n es fiable en sus predicciones positivas y captura la mayor칤a de los casos reales de la enfermedad. Este resultado valida la potencia del Transfer Learning para adaptarse a tareas espec칤ficas con datasets limitados, superando por mucho las limitaciones de entrenar desde cero.

---

## 游눠 Reflexi칩n Final y Aprendizaje Clave

Este proyecto demuestra emp칤ricamente que para tareas de clasificaci칩n de im치genes con **datasets peque침os**, entrenar una CNN desde cero es extremadamente desafiante y a menudo ineficaz debido al sobreajuste. La t칠cnica de **Transfer Learning** es una soluci칩n poderosa y pr치ctica, permitiendo aprovechar el conocimiento de modelos pre-entrenados para resolver problemas espec칤ficos con recursos de datos limitados.

El principal problema no fue la falta de una "herramienta mejorada" para la CNN desde cero, sino la **cantidad insuficiente de datos de entrenamiento 칰nicos para que una red tan compleja pudiera aprender a generalizar por s칤 misma**. El VGG16 ya es esa "herramienta mejorada" por su entrenamiento previo.

---

## 丘뒲잺 Consideraciones 칄ticas

Es crucial recordar que, aunque este proyecto es un ejercicio de aprendizaje, los modelos de IA aplicados a la salud, como la detecci칩n de enfermedades en im치genes m칠dicas, conllevan importantes responsabilidades 칠ticas:

* **Precisi칩n y Fiabilidad:** Un modelo de IA nunca debe reemplazar el juicio cl칤nico de un profesional m칠dico. Es una herramienta de apoyo. Errores (falsos positivos o falsos negativos) pueden tener consecuencias graves. En este caso, aunque el Recall es alto, un 9.4% de Falsos Negativos (casos de Neumon칤a no detectados) sigue siendo un riesgo significativo que debe ser mitigado en aplicaciones reales.
* **Sesgo del Modelo:** Es vital que el dataset de entrenamiento sea representativo de la poblaci칩n a la que se aplicar치 el modelo para evitar sesgos raciales, geogr치ficos o de equipo m칠dico.
* **Diversidad de Datos:** La falta de diversidad en la fuente de las im치genes (ej. diferentes m치quinas, etnias de pacientes, gravedades de la enfermedad) puede llevar a que el modelo funcione bien solo en los datos a los que ha sido expuesto, y mal en casos reales m치s variados.
* **Transparencia:** Comprender c칩mo el modelo toma decisiones es importante, aunque dif칤cil en redes neuronales profundas (problema de "caja negra").

Este proyecto sirve como una base para entender los desaf칤os y las soluciones en IA aplicada a la salud, pero siempre destacando la necesidad de validaci칩n rigurosa, consideraciones 칠ticas y la supervisi칩n humana en aplicaciones reales.
