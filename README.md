Dataset https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia 


# Detecci칩n de Neumon칤a en Radiograf칤as de T칩rax: Un Estudio de Caso de Aprendizaje Profundo

---

## 游늯 Resumen del Proyecto

Este proyecto explora la aplicaci칩n de Redes Neuronales Convolucionales (CNNs) para clasificar radiograf칤as de t칩rax en dos categor칤as: **Normal** y **Neumon칤a**. A trav칠s de este trabajo, se compara el rendimiento de un modelo CNN entrenado "desde cero" (manual) con un modelo que utiliza la potente t칠cnica de **Transfer Learning** (VGG16), destacando los desaf칤os del entrenamiento con datasets limitados y la importancia de las estrategias de IA.

---

## 游 Objetivo de Aprendizaje

El prop칩sito principal de este proyecto es did치ctico:

* **Comprender las Limitaciones de CNNs desde Cero:** Demostrar c칩mo una red neuronal, incluso con aumento de datos, puede fallar en aprender patrones complejos y tender a la **memorizaci칩n (sobreajuste)** cuando el volumen de datos de entrenamiento es muy escaso.
* **Dominar el Transfer Learning:** Ilustrar la eficacia y la necesidad del Transfer Learning para tareas de clasificaci칩n de im치genes con datasets peque침os, aprovechando el conocimiento pre-entrenado de modelos de vanguardia.
* **Manejo de Datos:** Entender la importancia del balance del dataset y las implicaciones de las estrategias de submuestreo vs. sobremuestreo/ponderaci칩n de clases.
* **Interpretaci칩n de M칠tricas:** Aprender a leer y entender m칠tricas clave como Accuracy, Precision, Recall y AUC en el contexto de clasificaci칩n binaria, especialmente para detectar problemas como el sesgo del modelo.

---

## 游늬 Estructura del Dataset

El dataset utilizado consta de radiograf칤as de t칩rax, dividido en conjuntos de entrenamiento, validaci칩n y prueba. Cada conjunto est치 perfectamente **balanceado** con 240 im치genes de la clase "Normal" y 240 im치genes de la clase "Neumon칤a".

* **`DATOS235/`**
    * **`train/`**
        * `normal/` (240 im치genes)
        * `pneumonia/` (240 im치genes)
    * **`val/`**
        * `normal/` (240 im치genes)
        * `pneumonia/` (240 im치genes)
    * **`test/`**
        * `normal/` (240 im치genes)
        * `pneumonia/` (240 im치genes)

**Nota sobre el balance:** Se opt칩 por submuestrear las clases con m치s im치genes para lograr un balance perfecto. Si bien esto ayuda a prevenir el sesgo hacia la clase mayoritaria, es importante reconocer que se descart칩 una cantidad considerable de datos 칰nicos que podr칤an haber mejorado a칰n m치s el rendimiento general del modelo si se hubieran utilizado con otras estrategias (como ponderaci칩n de clases o aumento de datos para la minoritaria).

---

## 游빍 Enfoques Implementados y Conclusiones

Se exploraron dos enfoques principales para la clasificaci칩n de im치genes:

### 1. Modelo CNN Entrenado "Desde Cero"

* **Descripci칩n:** Se construy칩 una Red Neuronal Convolucional (CNN) con capas como `Conv2D`, `MaxPooling2D`, `BatchNormalization`, `Flatten`, `Dense` y `Dropout`, intentando variar el n칰mero de filtros (ej. 16-32-64, 32-64-128) y el `batch_size`. Se aplic칩 **aumento de datos (data augmentation)** extensivo para intentar diversificar el dataset limitado.

* **Resultados T칤picos en Test:**
    * Loss: ~2.1249
    * Accuracy: ~0.5000
    * Precision: ~0.5000
    * Recall: ~1.0000
    * AUC: ~0.8238

* **Conclusi칩n:** Este enfoque **fracas칩 en la generalizaci칩n**. Las m칠tricas de prueba (`Accuracy` del 50%, `Precision` del 50%, `Recall` del 100%) revelan un **sobreajuste severo y un sesgo**. El modelo no aprendi칩 a distinguir entre "Normal" y "Neumon칤a"; en su lugar, **simplemente memoriz칩 las im치genes de entrenamiento** y termin칩 prediciendo sistem치ticamente una sola clase (probablemente "Neumon칤a") para todas las entradas en los conjuntos de validaci칩n y prueba. La **cantidad extremadamente limitada de im치genes 칰nicas (480 en entrenamiento)** impidi칩 que la CNN aprendiera patrones robustos y generalizables, incluso con el apoyo de la data augmentation.

### 2. Modelo Basado en Transfer Learning (VGG16)

* **Descripci칩n:** Se utiliz칩 la arquitectura **VGG16**, un modelo pre-entrenado en el gigantesco dataset ImageNet. Se carg칩 VGG16 **sin sus capas clasificatorias (`include_top=False`)** y sus capas convolucionales se **congelaron (`layer.trainable = False`)**. Luego, se a침adieron capas personalizadas (`Flatten`, `Dense`, `Dropout`, `Dense(1, sigmoid)`) en la parte superior para la clasificaci칩n binaria. Se entren칩 esta nueva "cabeza" clasificatoria y, en una segunda fase, se realiz칩 un **fine-tuning** (descongelando las 칰ltimas capas convolucionales de VGG16) con un `learning_rate` m치s bajo.

* **Resultados Reportados (Ejemplo de 칠xito):**
    * Accuracy: ~76.71%
    * Precision: ~95.62%
    * Recall: ~55.98%

* **Conclusi칩n:** El **Transfer Learning fue la estrategia funcional y exitosa**. A diferencia del modelo desde cero, VGG16 ya posee un vasto "conocimiento" de caracter칤sticas visuales generales (bordes, texturas, formas) aprendidas de millones de im치genes. Al congelar sus capas, lo utilizamos como un potente extractor de caracter칤sticas, y solo entrenamos las pocas capas nuevas para nuestra tarea espec칤fica. Esto **evit칩 el sobreajuste severo** y permiti칩 al modelo aprender patrones discriminativos de las radiograf칤as de t칩rax, obteniendo un rendimiento significativamente superior y 칰til.

---

## 游눠 Reflexi칩n Final y Aprendizaje Clave

Este proyecto demuestra emp칤ricamente que para tareas de clasificaci칩n de im치genes con **datasets peque침os**, entrenar una CNN desde cero es extremadamente desafiante y a menudo ineficaz debido al sobreajuste. La t칠cnica de **Transfer Learning** es una soluci칩n poderosa y pr치ctica, permitiendo aprovechar el conocimiento de modelos pre-entrenados para resolver problemas espec칤ficos con recursos de datos limitados.

El principal problema no fue la falta de una "herramienta mejorada" para la CNN desde cero, sino la **cantidad insuficiente de datos de entrenamiento 칰nicos para que una red tan compleja pudiera aprender a generalizar por s칤 misma**. El VGG16 ya es esa "herramienta mejorada" por su entrenamiento previo.

---

## 丘뒲잺 Consideraciones 칄ticas

Es crucial recordar que, aunque este proyecto es un ejercicio de aprendizaje, los modelos de IA aplicados a la salud, como la detecci칩n de enfermedades en im치genes m칠dicas, conllevan importantes responsabilidades 칠ticas:

* **Precisi칩n y Fiabilidad:** Un modelo de IA nunca debe reemplazar el juicio cl칤nico de un profesional m칠dico. Es una herramienta de apoyo. Errores (falsos positivos o falsos negativos) pueden tener consecuencias graves.
* **Sesgo del Modelo:** El rendimiento del `Recall` (capacidad de detectar todos los casos positivos) es especialmente cr칤tico en diagn칩stico m칠dico. Un `Recall` bajo (como el ~56% en este ejemplo) significa que el modelo falla en identificar casi la mitad de los casos de neumon칤a, lo cual es inaceptable en un escenario cl칤nico. Es vital optimizar esta m칠trica.
* **Diversidad de Datos:** Si bien se balance칩 el dataset, la falta de diversidad en la fuente de las im치genes (ej. diferentes m치quinas, etnias de pacientes, gravedades de la enfermedad) puede llevar a que el modelo funcione bien solo en los datos a los que ha sido expuesto, y mal en casos reales m치s variados.
* **Transparencia:** Comprender c칩mo el modelo toma decisiones es importante, aunque dif칤cil en redes neuronales profundas (problema de "caja negra").

Este proyecto sirve como una base para entender los desaf칤os y las soluciones en IA aplicada a la salud, pero siempre destacando la necesidad de validaci칩n rigurosa, consideraciones 칠ticas y la supervisi칩n humana en aplicaciones reales.
